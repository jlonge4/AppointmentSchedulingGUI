{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMk4SsBO2eTjEGesuu55+xI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlonge4/AppointmentSchedulingGUI/blob/main/faiss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2i_2V5kHrMFO"
      },
      "outputs": [],
      "source": [
        "pip install -qU langchain openai llama-index faiss-cpu sentence_transformers chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import os\n",
        "import openai\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=key,\n",
        "    temperature=0,\n",
        "    model_name=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "id": "7eHcV6w_rb_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "14LltcEarlzi"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "# initialize sentence transformer model\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "# create sentence embeddings\n"
      ],
      "metadata": {
        "id": "hwzYAiy8h5hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "two_web_links = [\"https://www.databricks.com/\",\"https://help.databricks.com\",\"https://databricks.com/try-databricks\",\"https://help.databricks.com/s/\",\"https://docs.databricks.com\",\"https://kb.databricks.com/\",\"http://docs.databricks.com/getting-started/index.html\",\"http://docs.databricks.com/introduction/index.html\",\"http://docs.databricks.com/getting-started/tutorials/index.html\",\"http://docs.databricks.com/release-notes/index.html\",\"http://docs.databricks.com/ingestion/index.html\",\"http://docs.databricks.com/exploratory-data-analysis/index.html\",\"http://docs.databricks.com/data-preparation/index.html\",\"http://docs.databricks.com/data-sharing/index.html\",\"http://docs.databricks.com/marketplace/index.html\",\"http://docs.databricks.com/workspace-index.html\",\"http://docs.databricks.com/machine-learning/index.html\",\"http://docs.databricks.com/sql/index.html\",\"http://docs.databricks.com/delta/index.html\",\"http://docs.databricks.com/dev-tools/index.html\",\"http://docs.databricks.com/integrations/index.html\",\"http://docs.databricks.com/administration-guide/index.html\",\"http://docs.databricks.com/security/index.html\",\"http://docs.databricks.com/data-governance/index.html\",\"http://docs.databricks.com/lakehouse-architecture/index.html\",\"http://docs.databricks.com/reference/api.html\",\"http://docs.databricks.com/resources/index.html\",\"http://docs.databricks.com/whats-coming.html\",\"http://docs.databricks.com/archive/index.html\",\"http://docs.databricks.com/lakehouse/index.html\",\"http://docs.databricks.com/getting-started/quick-start.html\",\"http://docs.databricks.com/getting-started/etl-quick-start.html\",\"http://docs.databricks.com/getting-started/lakehouse-e2e.html\",\"http://docs.databricks.com/getting-started/free-training.html\",\"http://docs.databricks.com/sql/language-manual/index.html\",\"http://docs.databricks.com/error-messages/index.html\",\"http://www.apache.org/\",\"https://databricks.com/privacy-policy\",\"https://databricks.com/terms-of-use\"]\n",
        "web_links = [\"https://www.pinecone.io/learn/vector-embeddings/\", \"https://www.featureform.com/post/the-definitive-guide-to-embeddings\"]\n",
        "loader = WebBaseLoader(web_links)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "nbdLOf9gfWLl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import metadata\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "malCge8zfdIq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "for d in all_splits:\n",
        "  docs.append(d.page_content)"
      ],
      "metadata": {
        "id": "oOae0Y_PisZD"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "dXwMAQU9lq3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDEXFLATL2"
      ],
      "metadata": {
        "id": "ct_s3fgGgLIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "vectorstore = FAISS.from_documents(all_splits, embedding_function)"
      ],
      "metadata": {
        "id": "hdJcEmUwePDV"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "query = 'What does pinecone define as embeddings'\n",
        "\n",
        "chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)\n",
        "\n",
        "chat_history = []\n",
        "start = time.time()\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPXt_oOmoBoA",
        "outputId": "c2affca9-ed81-49a8-8fc8-b0ab14af8007"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9789793491363525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L2 = result['answer']"
      ],
      "metadata": {
        "id": "d9lbBA3-q4Fe"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDEXIVFFLAT"
      ],
      "metadata": {
        "id": "nkHbsBV6gOl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings = model.encode(docs)\n",
        "d = sentence_embeddings.shape[1]\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKgg9zvoguM1",
        "outputId": "59e08ec7-d119-45fc-ec18-c3bed3e331a9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "nlist = 16  # how many cells\n",
        "quantizer = faiss.IndexFlatL2(d)\n",
        "index = faiss.IndexIVFFlat(quantizer,d, nlist)"
      ],
      "metadata": {
        "id": "_juf2U_KggCc"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.train(sentence_embeddings)\n",
        "index.add(sentence_embeddings)"
      ],
      "metadata": {
        "id": "BOB_BDxvnA-q"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ivf():\n",
        "  k = 4\n",
        "  xq = model.encode([query])\n",
        "  D, I = index.search(xq, k)\n",
        "  print(I)\n",
        "  return I[0][0]\n"
      ],
      "metadata": {
        "id": "Ee9FTPeBn0fS"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"source\"],\n",
        "    template=\"Given the context ### {source}### What does pinecone define as embeddings?\",\n",
        ")\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "start = time.time()\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "\n",
        "IVFFLAT = chain.run(docs[get_ivf()])\n",
        "print(IVFFLAT)\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjuf-_xPfC6H",
        "outputId": "77691937-108e-4bcc-dc55-11ebdb544013"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16 48  5 37]]\n",
            "\n",
            "\n",
            "Embeddings are numerical representations of words, phrases, and other elements of the text. These representations are derived from a machine learning model such as Word2Vec or BERT that \"learns\" the relationships between words from large corpuses of text and then assigns a vector to each word. Embeddings capture the semantic relationship between words by considering how they are used in the context of the text.\n",
            "3.01558780670166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDEXIVFPQ"
      ],
      "metadata": {
        "id": "homQFPeCri3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = 4  # number of centroid IDs in final compressed vectors\n",
        "bits = 4 # number of bits in each centroid\n",
        "\n",
        "quantizer = faiss.IndexFlatL2(d)  # we keep the same L2 distance flat index\n",
        "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits)"
      ],
      "metadata": {
        "id": "HK0UNEjGezcv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.train(sentence_embeddings)\n",
        "index.add(sentence_embeddings)\n",
        "index.nprobe = 10  # align to previous IndexIVFFlat nprobe value"
      ],
      "metadata": {
        "id": "g6sE4OU-fGUD"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ivfpq():\n",
        "  D, I = index.search(xq, k)\n",
        "  print(I)\n",
        "  return I[0][0]"
      ],
      "metadata": {
        "id": "fIZepw4or5Xl"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"source\"],\n",
        "    template=\"Given the context ### {source}### What does pinecone define as embeddings?\",\n",
        ")\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "start = time.time()\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "result = chain.run(docs[get_ivfpq()])\n",
        "print(result)\n",
        "IVFPQ = result\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kn6CMA8sO8T",
        "outputId": "a98d20be-e388-4803-dc61-38d8b2344dd0"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16 48  5 37]]\n",
            "\n",
            "\n",
            "Pinecone defines embeddings as numerical representations of text that capture the semantic relationships among words in the text. Embeddings are used to represent word meaning and can be used to help computers understand the context of words in a sentence.\n",
            "1.8402493000030518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "times = {\"INDEXFLATL2\": 3.978,\n",
        " \"INDEXIVFFLAT\": 3.015,\n",
        " \"INDEXIVFPQ\": 1.840}\n",
        "from pprint import pprint\n",
        "pprint(str(times).strip('{').strip(',').strip('}'))\n",
        "answers = times = {\"INDEXFLATL2\": L2,\n",
        " \"INDEXIVFFLAT\": IVFFLAT.strip('\\n'),\n",
        " \"INDEXIVFPQ\": IVFPQ.strip('\\n')}\n",
        "print('\\n')\n",
        "pprint(answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y9g0lWYsbSb",
        "outputId": "9b18b053-e7e6-4ee1-fff4-652e84edbc42"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"'INDEXFLATL2': 3.978, 'INDEXIVFFLAT': 3.015, 'INDEXIVFPQ': 1.84\"\n",
            "\n",
            "\n",
            "{'INDEXFLATL2': ' Pinecone does not define embeddings. Embeddings are a '\n",
            "                'concept used in machine learning and natural language '\n",
            "                'processing, and they are central to many algorithms. '\n",
            "                'Embeddings are used in applications like recommendation '\n",
            "                'engines, voice assistants, language translators, and more.',\n",
            " 'INDEXIVFFLAT': 'Embeddings are numerical representations of words, phrases, '\n",
            "                 'and other elements of the text. These representations are '\n",
            "                 'derived from a machine learning model such as Word2Vec or '\n",
            "                 'BERT that \"learns\" the relationships between words from '\n",
            "                 'large corpuses of text and then assigns a vector to each '\n",
            "                 'word. Embeddings capture the semantic relationship between '\n",
            "                 'words by considering how they are used in the context of the '\n",
            "                 'text.',\n",
            " 'INDEXIVFPQ': 'Pinecone defines embeddings as numerical representations of '\n",
            "               'text that capture the semantic relationships among words in '\n",
            "               'the text. Embeddings are used to represent word meaning and '\n",
            "               'can be used to help computers understand the context of words '\n",
            "               'in a sentence.'}\n"
          ]
        }
      ]
    }
  ]
}